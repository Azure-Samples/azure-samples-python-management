# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------

# - other dependence -
# azure-mgmt-monitor==6.0.2
# azure-mgmt-alertsmanagement==2.0.0b2
# - end -

from azure.identity import DefaultAzureCredential
from azure.mgmt.containerservice import ContainerServiceClient
from azure.mgmt.monitor import  MonitorManagementClient
from azure.mgmt.alertsmanagement import AlertsManagementClient
from dotenv import load_dotenv
import os

def main():
    load_dotenv()
    AZURE_SUBSCRIPTION_ID = os.environ.get("AZURE_SUBSCRIPTION_ID", None)
    RESOURCE_GROUP_NAME = os.environ.get("RESOURCE_GROUP_NAME", None)
    AZURE_LOCATION = os.environ.get("AZURE_LOCATION", None)
    MANAGED_CLUSTERS_NAME = os.environ.get("MANAGED_CLUSTERS_NAME", None)
    MANAGED_CLUSTERS_ID = os.environ.get("MANAGED_CLUSTERS_ID", None)
    MONITOR_WORKSPACE_NAME = os.environ.get("MONITOR_WORKSPACE_NAME", None)

    # Create client
    containerservice_client = ContainerServiceClient(
        subscription_id=AZURE_SUBSCRIPTION_ID,
        credential=DefaultAzureCredential(),
    )
    monitor_client = MonitorManagementClient(
        subscription_id=AZURE_SUBSCRIPTION_ID,
        credential=DefaultAzureCredential(),
    )
    alert_management_client = AlertsManagementClient(
        subscription_id=AZURE_SUBSCRIPTION_ID,
        credential=DefaultAzureCredential(),
    )

    # Create azure monitor workspace
    azure_monitor_workspace_id = monitor_client.azure_monitor_workspaces.create(
        resource_group_name=RESOURCE_GROUP_NAME,
        azure_monitor_workspace_name=MONITOR_WORKSPACE_NAME,
        azure_monitor_workspace_properties={
            "location": AZURE_LOCATION,
        },
    ).id

    # Create data collection endpoint
    data_collection_endpoint_id = monitor_client.data_collection_endpoints.create(
        resource_group_name=RESOURCE_GROUP_NAME,
        data_collection_endpoint_name=f"MSProm-{AZURE_LOCATION}-{MANAGED_CLUSTERS_NAME}",
        body={
            "location": AZURE_LOCATION,
            "kind": "Linux",
            "properties": {"description": "Data Collection Endpoint for AKS"},
        },
    ).id

    # Create data collection rule
    data_collection_rule_id = monitor_client.data_collection_rules.create(
        resource_group_name=RESOURCE_GROUP_NAME,
        data_collection_rule_name=f"MSProm-{AZURE_LOCATION}-{MANAGED_CLUSTERS_NAME}",
        body={
            "location": AZURE_LOCATION,
            "kind": "Linux",
            "properties": {
                "dataCollectionEndpointId": data_collection_endpoint_id,
                "dataSources": {
                    "prometheusForwarder": [{"name": "PrometheusDataSource", "streams": ["Microsoft-PrometheusMetrics"], "labelIncludeFilter": {}}]
                },
                "dataFlows": [{"destinations": ["MonitoringAccount1"], "streams": ["Microsoft-PrometheusMetrics"]}],
                "description": "DCR description", 
                "destinations": {"monitoringAccounts": [{"accountResourceId": azure_monitor_workspace_id, "name": "MonitoringAccount1"}]}
            },
        },
    ).id

    # Create data collection rule association
    monitor_client.data_collection_rule_associations.create(
        resource_uri=MANAGED_CLUSTERS_ID,
        association_name="ContainerInsightsMetricsExtension",
        body={
            "location": AZURE_LOCATION,
            "properties": {
                "dataCollectionRuleId": data_collection_rule_id,
                "description": "Promtheus data collection association between DCR, DCE and target AKS resource",
            },
        },
    )

    # Create prometheus rule groups
    alert_management_client.prometheus_rule_groups.create_or_update(
        resource_group_name=RESOURCE_GROUP_NAME,
        rule_group_name=f"NodeRecordingRulesRuleGroup-{MANAGED_CLUSTERS_NAME}",
        parameters={
            "location": AZURE_LOCATION,
            "type": "Microsoft.AlertsManagement/prometheusRuleGroups",
            "properties": {
                "scopes": [azure_monitor_workspace_id, MANAGED_CLUSTERS_ID],
                "enabled": True,
                "clusterName": MANAGED_CLUSTERS_NAME,
                "interval": "PT1M",
                # Recommended rules template
                "rules": [
                    {"record": "instance:node_num_cpu:sum", "expression": "count without (cpu, mode) (  node_cpu_seconds_total{job=\"node\",mode=\"idle\"})"}, 
                    {"record": "instance:node_cpu_utilisation:rate5m", "expression": "1 - avg without (cpu) (  sum without (mode) (rate(node_cpu_seconds_total{job=\"node\", mode=~\"idle|iowait|steal\"}[5m])))"}, 
                    {"record": "instance:node_load1_per_cpu:ratio", "expression": "(  node_load1{job=\"node\"}/  instance:node_num_cpu:sum{job=\"node\"})"}, 
                    {"record": "instance:node_memory_utilisation:ratio", "expression": "1 - (  (    node_memory_MemAvailable_bytes{job=\"node\"}    or    (      node_memory_Buffers_bytes{job=\"node\"}      +      node_memory_Cached_bytes{job=\"node\"}      +      node_memory_MemFree_bytes{job=\"node\"}      +      node_memory_Slab_bytes{job=\"node\"}    )  )/  node_memory_MemTotal_bytes{job=\"node\"})"}, 
                    {"record": "instance:node_vmstat_pgmajfault:rate5m", "expression": "rate(node_vmstat_pgmajfault{job=\"node\"}[5m])"}, 
                    {"record": "instance_device:node_disk_io_time_seconds:rate5m", "expression": "rate(node_disk_io_time_seconds_total{job=\"node\", device!=\"\"}[5m])"}, 
                    {"record": "instance_device:node_disk_io_time_weighted_seconds:rate5m", "expression": "rate(node_disk_io_time_weighted_seconds_total{job=\"node\", device!=\"\"}[5m])"}, 
                    {"record": "instance:node_network_receive_bytes_excluding_lo:rate5m", "expression": "sum without (device) (  rate(node_network_receive_bytes_total{job=\"node\", device!=\"lo\"}[5m]))"}, 
                    {"record": "instance:node_network_transmit_bytes_excluding_lo:rate5m", "expression": "sum without (device) (  rate(node_network_transmit_bytes_total{job=\"node\", device!=\"lo\"}[5m]))"}, 
                    {"record": "instance:node_network_receive_drop_excluding_lo:rate5m", "expression": "sum without (device) (  rate(node_network_receive_drop_total{job=\"node\", device!=\"lo\"}[5m]))"}, 
                    {"record": "instance:node_network_transmit_drop_excluding_lo:rate5m", "expression": "sum without (device) (  rate(node_network_transmit_drop_total{job=\"node\", device!=\"lo\"}[5m]))"}
                ]
            }
        },
    )

    alert_management_client.prometheus_rule_groups.create_or_update(
        resource_group_name=RESOURCE_GROUP_NAME,
        rule_group_name=f"KubernetesRecordingRulesRuleGroup-{MANAGED_CLUSTERS_NAME}",
        parameters={
            "location": AZURE_LOCATION,
            "type": "Microsoft.AlertsManagement/prometheusRuleGroups",
            "properties": {
                "scopes": [azure_monitor_workspace_id, MANAGED_CLUSTERS_ID],
                "enabled": True,
                "clusterName": MANAGED_CLUSTERS_NAME,
                "interval": "PT1M",
                # Recommended rules template
                "rules": [
                    {"record": "node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate", "expression": "sum by (cluster, namespace, pod, container) (  irate(container_cpu_usage_seconds_total{job=\"cadvisor\", image!=\"\"}[5m])) * on (cluster, namespace, pod) group_left(node) topk by (cluster, namespace, pod) (  1, max by(cluster, namespace, pod, node) (kube_pod_info{node!=\"\"}))"}, 
                    {"record": "node_namespace_pod_container:container_memory_working_set_bytes", "expression": "container_memory_working_set_bytes{job=\"cadvisor\", image!=\"\"}* on (namespace, pod) group_left(node) topk by(namespace, pod) (1,  max by(namespace, pod, node) (kube_pod_info{node!=\"\"}))"}, 
                    {"record": "node_namespace_pod_container:container_memory_rss", "expression": "container_memory_rss{job=\"cadvisor\", image!=\"\"}* on (namespace, pod) group_left(node) topk by(namespace, pod) (1,  max by(namespace, pod, node) (kube_pod_info{node!=\"\"}))"}, 
                    {"record": "node_namespace_pod_container:container_memory_cache", "expression": "container_memory_cache{job=\"cadvisor\", image!=\"\"}* on (namespace, pod) group_left(node) topk by(namespace, pod) (1,  max by(namespace, pod, node) (kube_pod_info{node!=\"\"}))"}, 
                    {"record": "node_namespace_pod_container:container_memory_swap", "expression": "container_memory_swap{job=\"cadvisor\", image!=\"\"}* on (namespace, pod) group_left(node) topk by(namespace, pod) (1,  max by(namespace, pod, node) (kube_pod_info{node!=\"\"}))"}, 
                    {"record": "cluster:namespace:pod_memory:active:kube_pod_container_resource_requests", "expression": "kube_pod_container_resource_requests{resource=\"memory\",job=\"kube-state-metrics\"}  * on (namespace, pod, cluster)group_left() max by (namespace, pod, cluster) (  (kube_pod_status_phase{phase=~\"Pending|Running\"} == 1))"}, 
                    {"record": "namespace_memory:kube_pod_container_resource_requests:sum", "expression": "sum by (namespace, cluster) (    sum by (namespace, pod, cluster) (        max by (namespace, pod, container, cluster) (          kube_pod_container_resource_requests{resource=\"memory\",job=\"kube-state-metrics\"}        ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (          kube_pod_status_phase{phase=~\"Pending|Running\"} == 1        )    ))"}, 
                    {"record": "cluster:namespace:pod_cpu:active:kube_pod_container_resource_requests", "expression": "kube_pod_container_resource_requests{resource=\"cpu\",job=\"kube-state-metrics\"}  * on (namespace, pod, cluster)group_left() max by (namespace, pod, cluster) (  (kube_pod_status_phase{phase=~\"Pending|Running\"} == 1))"}, 
                    {"record": "namespace_cpu:kube_pod_container_resource_requests:sum", "expression": "sum by (namespace, cluster) (    sum by (namespace, pod, cluster) (        max by (namespace, pod, container, cluster) (          kube_pod_container_resource_requests{resource=\"cpu\",job=\"kube-state-metrics\"}        ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (          kube_pod_status_phase{phase=~\"Pending|Running\"} == 1        )    ))"}, 
                    {"record": "cluster:namespace:pod_memory:active:kube_pod_container_resource_limits", "expression": "kube_pod_container_resource_limits{resource=\"memory\",job=\"kube-state-metrics\"}  * on (namespace, pod, cluster)group_left() max by (namespace, pod, cluster) (  (kube_pod_status_phase{phase=~\"Pending|Running\"} == 1))"}, 
                    {"record": "namespace_memory:kube_pod_container_resource_limits:sum", "expression": "sum by (namespace, cluster) (    sum by (namespace, pod, cluster) (        max by (namespace, pod, container, cluster) (          kube_pod_container_resource_limits{resource=\"memory\",job=\"kube-state-metrics\"}        ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (          kube_pod_status_phase{phase=~\"Pending|Running\"} == 1        )    ))"}, 
                    {"record": "cluster:namespace:pod_cpu:active:kube_pod_container_resource_limits", "expression": "kube_pod_container_resource_limits{resource=\"cpu\",job=\"kube-state-metrics\"}  * on (namespace, pod, cluster)group_left() max by (namespace, pod, cluster) ( (kube_pod_status_phase{phase=~\"Pending|Running\"} == 1) )"}, 
                    {"record": "namespace_cpu:kube_pod_container_resource_limits:sum", "expression": "sum by (namespace, cluster) (    sum by (namespace, pod, cluster) (        max by (namespace, pod, container, cluster) (          kube_pod_container_resource_limits{resource=\"cpu\",job=\"kube-state-metrics\"}        ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (          kube_pod_status_phase{phase=~\"Pending|Running\"} == 1        )    ))"}, 
                    {"record": "namespace_workload_pod:kube_pod_owner:relabel", "expression": "max by (cluster, namespace, workload, pod) (  label_replace(    label_replace(      kube_pod_owner{job=\"kube-state-metrics\", owner_kind=\"ReplicaSet\"},      \"replicaset\", \"$1\", \"owner_name\", \"(.*)\"    ) * on(replicaset, namespace) group_left(owner_name) topk by(replicaset, namespace) (      1, max by (replicaset, namespace, owner_name) (        kube_replicaset_owner{job=\"kube-state-metrics\"}      )    ),    \"workload\", \"$1\", \"owner_name\", \"(.*)\"  ))", "labels": {"workload_type": "deployment"}}, 
                    {"record": "namespace_workload_pod:kube_pod_owner:relabel", "expression": "max by (cluster, namespace, workload, pod) (  label_replace(    kube_pod_owner{job=\"kube-state-metrics\", owner_kind=\"DaemonSet\"},    \"workload\", \"$1\", \"owner_name\", \"(.*)\"  ))", "labels": {"workload_type": "daemonset"}}, 
                    {"record": "namespace_workload_pod:kube_pod_owner:relabel", "expression": "max by (cluster, namespace, workload, pod) (  label_replace(    kube_pod_owner{job=\"kube-state-metrics\", owner_kind=\"StatefulSet\"},    \"workload\", \"$1\", \"owner_name\", \"(.*)\"  ))", "labels": {"workload_type": "statefulset"}}, 
                    {"record": "namespace_workload_pod:kube_pod_owner:relabel", "expression": "max by (cluster, namespace, workload, pod) (  label_replace(    kube_pod_owner{job=\"kube-state-metrics\", owner_kind=\"Job\"},    \"workload\", \"$1\", \"owner_name\", \"(.*)\"  ))", "labels": {"workload_type": "job"}}, 
                    {"record": ":node_memory_MemAvailable_bytes:sum", "expression": "sum(  node_memory_MemAvailable_bytes{job=\"node\"} or  (    node_memory_Buffers_bytes{job=\"node\"} +    node_memory_Cached_bytes{job=\"node\"} +    node_memory_MemFree_bytes{job=\"node\"} +    node_memory_Slab_bytes{job=\"node\"}  )) by (cluster)"}, 
                    {"record": "cluster:node_cpu:ratio_rate5m", "expression": "sum(rate(node_cpu_seconds_total{job=\"node\",mode!=\"idle\",mode!=\"iowait\",mode!=\"steal\"}[5m])) by (cluster) /count(sum(node_cpu_seconds_total{job=\"node\"}) by (cluster, instance, cpu)) by (cluster)"}
                ]
            }
        },
    )

    # Update Managed Cluster
    managed_cluster = containerservice_client.managed_clusters.begin_create_or_update(
        resource_group_name=RESOURCE_GROUP_NAME,
        resource_name=MANAGED_CLUSTERS_NAME,
        parameters={
            "location": AZURE_LOCATION,
            "azureMonitorProfile": {"metrics": {"enabled": True}}
        }
    ).result()

if __name__ == "__main__":
    main()
